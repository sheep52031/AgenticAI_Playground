{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TextSQL RAG Pipeline 學習筆記\n",
    "\n",
    "本筆記本將詳細介紹如何構建一個完整的 textSQL RAG (Retrieval-Augmented Generation) 流水線。\n",
    "\n",
    "## 目錄\n",
    "1. [RAG 概念介紹](#1-rag-概念介紹)\n",
    "2. [TextSQL 基礎](#2-textsql-基礎)\n",
    "3. [環境設置](#3-環境設置)\n",
    "4. [數據預處理](#4-數據預處理)\n",
    "5. [向量化與索引](#5-向量化與索引)\n",
    "6. [檢索系統](#6-檢索系統)\n",
    "7. [SQL 生成](#7-sql-生成)\n",
    "8. [完整流水線](#8-完整流水線)\n",
    "9. [評估與優化](#9-評估與優化)\n",
    "10. [實際應用案例](#10-實際應用案例)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. RAG 概念介紹\n",
    "\n",
    "### 什麼是 RAG？\n",
    "RAG（Retrieval-Augmented Generation）是一種結合了檢索和生成的架構：\n",
    "1. **檢索階段**：從知識庫中找到相關信息\n",
    "2. **生成階段**：基於檢索到的信息生成回答\n",
    "\n",
    "### TextSQL RAG 的特點\n",
    "- 專注於自然語言到 SQL 查詢的轉換\n",
    "- 結合數據庫模式信息\n",
    "- 支持複雜的數據庫查詢生成"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 基本概念示例\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any\n",
    "\n",
    "# RAG 流程示意\n",
    "class SimpleRAGConcept:\n",
    "    def __init__(self):\n",
    "        self.knowledge_base = []\n",
    "        self.query_history = []\n",
    "    \n",
    "    def retrieve(self, query: str) -> List[str]:\n",
    "        \"\"\"檢索相關信息\"\"\"\n",
    "        # 這裡是簡化的檢索邏輯\n",
    "        relevant_docs = [doc for doc in self.knowledge_base \n",
    "                        if any(word.lower() in doc.lower() for word in query.split())]\n",
    "        return relevant_docs[:3]  # 返回前3個相關文檔\n",
    "    \n",
    "    def generate(self, query: str, context: List[str]) -> str:\n",
    "        \"\"\"基於上下文生成回答\"\"\"\n",
    "        # 這裡是簡化的生成邏輯\n",
    "        return f\"基於上下文 {context} 對查詢 '{query}' 的回答\"\n",
    "    \n",
    "    def rag_pipeline(self, query: str) -> str:\n",
    "        \"\"\"完整的RAG流水線\"\"\"\n",
    "        # 1. 檢索\n",
    "        relevant_context = self.retrieve(query)\n",
    "        # 2. 生成\n",
    "        response = self.generate(query, relevant_context)\n",
    "        # 3. 記錄查詢歷史\n",
    "        self.query_history.append({'query': query, 'response': response})\n",
    "        return response\n",
    "\n",
    "# 示例使用\n",
    "rag_demo = SimpleRAGConcept()\n",
    "rag_demo.knowledge_base = [\n",
    "    \"用戶表包含用戶ID、姓名、郵箱等字段\",\n",
    "    \"訂單表記錄了所有的購買信息\",\n",
    "    \"產品表存儲產品的詳細信息\"\n",
    "]\n",
    "\n",
    "result = rag_demo.rag_pipeline(\"如何查詢用戶的訂單信息？\")\n",
    "print(\"RAG 示例結果:\")\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. TextSQL 基礎\n",
    "\n",
    "### 核心概念\n",
    "TextSQL 是將自然語言查詢轉換為 SQL 語句的過程。關鍵組件包括：\n",
    "- **Schema Understanding**: 理解數據庫結構\n",
    "- **Intent Recognition**: 識別用戶意圖\n",
    "- **SQL Generation**: 生成對應的SQL語句"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TextSQL 基礎組件\n",
    "class DatabaseSchema:\n",
    "    \"\"\"數據庫模式類\"\"\"\n",
    "    def __init__(self):\n",
    "        self.tables = {}\n",
    "        self.relationships = []\n",
    "    \n",
    "    def add_table(self, table_name: str, columns: Dict[str, str]):\n",
    "        \"\"\"添加表結構\"\"\"\n",
    "        self.tables[table_name] = columns\n",
    "    \n",
    "    def add_relationship(self, table1: str, column1: str, table2: str, column2: str):\n",
    "        \"\"\"添加表關係\"\"\"\n",
    "        self.relationships.append({\n",
    "            'from_table': table1,\n",
    "            'from_column': column1,\n",
    "            'to_table': table2,\n",
    "            'to_column': column2\n",
    "        })\n",
    "    \n",
    "    def get_schema_info(self) -> str:\n",
    "        \"\"\"獲取模式信息\"\"\"\n",
    "        schema_info = \"數據庫模式信息:\\n\"\n",
    "        for table, columns in self.tables.items():\n",
    "            schema_info += f\"表 {table}: {columns}\\n\"\n",
    "        return schema_info\n",
    "\n",
    "# 創建示例數據庫模式\n",
    "schema = DatabaseSchema()\n",
    "schema.add_table('users', {\n",
    "    'user_id': 'INT PRIMARY KEY',\n",
    "    'name': 'VARCHAR(100)',\n",
    "    'email': 'VARCHAR(100)',\n",
    "    'created_at': 'DATETIME'\n",
    "})\n",
    "\n",
    "schema.add_table('orders', {\n",
    "    'order_id': 'INT PRIMARY KEY',\n",
    "    'user_id': 'INT',\n",
    "    'product_id': 'INT',\n",
    "    'quantity': 'INT',\n",
    "    'order_date': 'DATETIME'\n",
    "})\n",
    "\n",
    "schema.add_table('products', {\n",
    "    'product_id': 'INT PRIMARY KEY',\n",
    "    'name': 'VARCHAR(100)',\n",
    "    'price': 'DECIMAL(10,2)',\n",
    "    'category': 'VARCHAR(50)'\n",
    "})\n",
    "\n",
    "schema.add_relationship('orders', 'user_id', 'users', 'user_id')\n",
    "schema.add_relationship('orders', 'product_id', 'products', 'product_id')\n",
    "\n",
    "print(schema.get_schema_info())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 環境設置\n",
    "\n",
    "### 安裝必要的庫"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 在 Kaggle 環境中安裝必要的包\n",
    "import sys\n",
    "import subprocess\n",
    "\n",
    "def install_package(package):\n",
    "    subprocess.check_call([sys.executable, \"-m\", \"pip\", \"install\", package])\n",
    "\n",
    "# 核心包列表\n",
    "packages = [\n",
    "    'transformers',\n",
    "    'torch',\n",
    "    'sentence-transformers',\n",
    "    'faiss-cpu',\n",
    "    'chromadb',\n",
    "    'langchain',\n",
    "    'openai',\n",
    "    'sqlparse',\n",
    "    'sqlite3'\n",
    "]\n",
    "\n",
    "print(\"正在安裝必要的包...\")\n",
    "for package in packages:\n",
    "    try:\n",
    "        install_package(package)\n",
    "        print(f\"✓ {package} 安裝成功\")\n",
    "    except Exception as e:\n",
    "        print(f\"✗ {package} 安裝失敗: {e}\")\n",
    "\n",
    "print(\"\\n環境設置完成！\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 導入必要的庫\n",
    "import os\n",
    "import json\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from typing import List, Dict, Any, Tuple\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# 向量化和檢索\n",
    "from sentence_transformers import SentenceTransformer\n",
    "import faiss\n",
    "\n",
    "# 自然語言處理\n",
    "from transformers import AutoTokenizer, AutoModel\n",
    "import torch\n",
    "\n",
    "# SQL 解析\n",
    "import sqlparse\n",
    "\n",
    "print(\"所有必要的庫已成功導入！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 數據預處理\n",
    "\n",
    "### 創建示例數據庫和數據"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建示例 SQLite 數據庫\n",
    "def create_sample_database():\n",
    "    \"\"\"創建示例數據庫\"\"\"\n",
    "    conn = sqlite3.connect('sample_ecommerce.db')\n",
    "    cursor = conn.cursor()\n",
    "    \n",
    "    # 創建用戶表\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS users (\n",
    "        user_id INTEGER PRIMARY KEY,\n",
    "        name TEXT NOT NULL,\n",
    "        email TEXT UNIQUE NOT NULL,\n",
    "        created_at DATETIME DEFAULT CURRENT_TIMESTAMP\n",
    "    )\n",
    "    ''')\n",
    "    \n",
    "    # 創建產品表\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS products (\n",
    "        product_id INTEGER PRIMARY KEY,\n",
    "        name TEXT NOT NULL,\n",
    "        price DECIMAL(10,2) NOT NULL,\n",
    "        category TEXT NOT NULL,\n",
    "        description TEXT\n",
    "    )\n",
    "    ''')\n",
    "    \n",
    "    # 創建訂單表\n",
    "    cursor.execute('''\n",
    "    CREATE TABLE IF NOT EXISTS orders (\n",
    "        order_id INTEGER PRIMARY KEY,\n",
    "        user_id INTEGER,\n",
    "        product_id INTEGER,\n",
    "        quantity INTEGER NOT NULL,\n",
    "        order_date DATETIME DEFAULT CURRENT_TIMESTAMP,\n",
    "        FOREIGN KEY (user_id) REFERENCES users (user_id),\n",
    "        FOREIGN KEY (product_id) REFERENCES products (product_id)\n",
    "    )\n",
    "    ''')\n",
    "    \n",
    "    # 插入示例數據\n",
    "    users_data = [\n",
    "        (1, '張三', 'zhang@example.com'),\n",
    "        (2, '李四', 'li@example.com'),\n",
    "        (3, '王五', 'wang@example.com')\n",
    "    ]\n",
    "    \n",
    "    products_data = [\n",
    "        (1, 'iPhone 15', 999.99, '電子產品', '最新款智能手機'),\n",
    "        (2, 'MacBook Pro', 1299.99, '電子產品', '專業筆記本電腦'),\n",
    "        (3, '咖啡機', 199.99, '家電', '全自動咖啡機'),\n",
    "        (4, '書籍：Python編程', 29.99, '圖書', 'Python編程入門教程')\n",
    "    ]\n",
    "    \n",
    "    orders_data = [\n",
    "        (1, 1, 1, 1),\n",
    "        (2, 1, 3, 1),\n",
    "        (3, 2, 2, 1),\n",
    "        (4, 3, 4, 2)\n",
    "    ]\n",
    "    \n",
    "    cursor.executemany('INSERT OR REPLACE INTO users (user_id, name, email) VALUES (?, ?, ?)', users_data)\n",
    "    cursor.executemany('INSERT OR REPLACE INTO products (product_id, name, price, category, description) VALUES (?, ?, ?, ?, ?)', products_data)\n",
    "    cursor.executemany('INSERT OR REPLACE INTO orders (order_id, user_id, product_id, quantity) VALUES (?, ?, ?, ?)', orders_data)\n",
    "    \n",
    "    conn.commit()\n",
    "    conn.close()\n",
    "    print(\"示例數據庫創建完成！\")\n",
    "\n",
    "# 創建數據庫\n",
    "create_sample_database()\n",
    "\n",
    "# 驗證數據\n",
    "def verify_database():\n",
    "    conn = sqlite3.connect('sample_ecommerce.db')\n",
    "    \n",
    "    print(\"用戶表:\")\n",
    "    users_df = pd.read_sql_query('SELECT * FROM users', conn)\n",
    "    print(users_df)\n",
    "    \n",
    "    print(\"\\n產品表:\")\n",
    "    products_df = pd.read_sql_query('SELECT * FROM products', conn)\n",
    "    print(products_df)\n",
    "    \n",
    "    print(\"\\n訂單表:\")\n",
    "    orders_df = pd.read_sql_query('SELECT * FROM orders', conn)\n",
    "    print(orders_df)\n",
    "    \n",
    "    conn.close()\n",
    "\n",
    "verify_database()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 準備訓練數據集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 創建自然語言到SQL的訓練數據集\n",
    "training_data = [\n",
    "    {\n",
    "        \"natural_language\": \"顯示所有用戶的信息\",\n",
    "        \"sql\": \"SELECT * FROM users;\",\n",
    "        \"explanation\": \"查詢用戶表中的所有記錄\"\n",
    "    },\n",
    "    {\n",
    "        \"natural_language\": \"找出價格超過500元的產品\",\n",
    "        \"sql\": \"SELECT * FROM products WHERE price > 500;\",\n",
    "        \"explanation\": \"使用WHERE子句過濾價格大於500的產品\"\n",
    "    },\n",
    "    {\n",
    "        \"natural_language\": \"統計每個用戶的訂單數量\",\n",
    "        \"sql\": \"SELECT u.name, COUNT(o.order_id) as order_count FROM users u LEFT JOIN orders o ON u.user_id = o.user_id GROUP BY u.user_id, u.name;\",\n",
    "        \"explanation\": \"使用JOIN和GROUP BY統計每個用戶的訂單數量\"\n",
    "    },\n",
    "    {\n",
    "        \"natural_language\": \"查找最貴的產品\",\n",
    "        \"sql\": \"SELECT * FROM products ORDER BY price DESC LIMIT 1;\",\n",
    "        \"explanation\": \"使用ORDER BY和LIMIT找到價格最高的產品\"\n",
    "    },\n",
    "    {\n",
    "        \"natural_language\": \"顯示用戶張三的所有訂單\",\n",
    "        \"sql\": \"SELECT o.*, p.name as product_name FROM orders o JOIN users u ON o.user_id = u.user_id JOIN products p ON o.product_id = p.product_id WHERE u.name = '張三';\",\n",
    "        \"explanation\": \"使用多表JOIN查詢特定用戶的訂單信息\"\n",
    "    },\n",
    "    {\n",
    "        \"natural_language\": \"計算每個類別的產品平均價格\",\n",
    "        \"sql\": \"SELECT category, AVG(price) as avg_price FROM products GROUP BY category;\",\n",
    "        \"explanation\": \"使用GROUP BY和AVG函數計算各類別的平均價格\"\n",
    "    },\n",
    "    {\n",
    "        \"natural_language\": \"找出沒有下過訂單的用戶\",\n",
    "        \"sql\": \"SELECT u.* FROM users u LEFT JOIN orders o ON u.user_id = o.user_id WHERE o.user_id IS NULL;\",\n",
    "        \"explanation\": \"使用LEFT JOIN和IS NULL找出沒有訂單的用戶\"\n",
    "    },\n",
    "    {\n",
    "        \"natural_language\": \"顯示銷量最高的產品\",\n",
    "        \"sql\": \"SELECT p.name, SUM(o.quantity) as total_sold FROM products p JOIN orders o ON p.product_id = o.product_id GROUP BY p.product_id, p.name ORDER BY total_sold DESC LIMIT 1;\",\n",
    "        \"explanation\": \"統計產品銷量並找出銷量最高的產品\"\n",
    "    }\n",
    "]\n",
    "\n",
    "# 保存訓練數據\n",
    "with open('training_data.json', 'w', encoding='utf-8') as f:\n",
    "    json.dump(training_data, f, ensure_ascii=False, indent=2)\n",
    "\n",
    "print(f\"訓練數據集包含 {len(training_data)} 個樣本\")\n",
    "print(\"\\n示例數據:\")\n",
    "for i, item in enumerate(training_data[:3]):\n",
    "    print(f\"\\n樣本 {i+1}:\")\n",
    "    print(f\"自然語言: {item['natural_language']}\")\n",
    "    print(f\"SQL: {item['sql']}\")\n",
    "    print(f\"說明: {item['explanation']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 向量化與索引\n",
    "\n",
    "### 使用句子嵌入模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 初始化句子嵌入模型\n",
    "class TextEmbedder:\n",
    "    def __init__(self, model_name='all-MiniLM-L6-v2'):\n",
    "        \"\"\"初始化文本嵌入器\"\"\"\n",
    "        try:\n",
    "            self.model = SentenceTransformer(model_name)\n",
    "            print(f\"成功加載模型: {model_name}\")\n",
    "        except Exception as e:\n",
    "            print(f\"模型加載失敗: {e}, 使用備用方案\")\n",
    "            # 備用方案：使用簡單的詞向量\n",
    "            self.model = None\n",
    "    \n",
    "    def encode(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"將文本編碼為向量\"\"\"\n",
    "        if self.model:\n",
    "            return self.model.encode(texts)\n",
    "        else:\n",
    "            # 簡單的備用編碼方案\n",
    "            return self._simple_encode(texts)\n",
    "    \n",
    "    def _simple_encode(self, texts: List[str]) -> np.ndarray:\n",
    "        \"\"\"簡單的文本編碼備用方案\"\"\"\n",
    "        # 這是一個簡化的實現，實際應用中應使用更複雜的方法\n",
    "        vocab = {}\n",
    "        for text in texts:\n",
    "            for word in text.lower().split():\n",
    "                if word not in vocab:\n",
    "                    vocab[word] = len(vocab)\n",
    "        \n",
    "        vectors = []\n",
    "        for text in texts:\n",
    "            vector = np.zeros(len(vocab))\n",
    "            for word in text.lower().split():\n",
    "                if word in vocab:\n",
    "                    vector[vocab[word]] = 1\n",
    "            vectors.append(vector)\n",
    "        \n",
    "        return np.array(vectors)\n",
    "\n",
    "# 初始化嵌入器\n",
    "embedder = TextEmbedder()\n",
    "\n",
    "# 測試嵌入功能\n",
    "test_texts = [\n",
    "    \"查詢所有用戶\",\n",
    "    \"顯示產品信息\",\n",
    "    \"統計訂單數量\"\n",
    "]\n",
    "\n",
    "embeddings = embedder.encode(test_texts)\n",
    "print(f\"文本嵌入維度: {embeddings.shape}\")\n",
    "print(f\"嵌入示例: {embeddings[0][:5]}...\")  # 顯示前5個維度"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 構建向量索引"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 構建FAISS向量索引\n",
    "class VectorIndex:\n",
    "    def __init__(self, dimension: int):\n",
    "        \"\"\"初始化向量索引\"\"\"\n",
    "        self.dimension = dimension\n",
    "        self.index = faiss.IndexFlatL2(dimension)  # L2距離索引\n",
    "        self.texts = []  # 存儲原始文本\n",
    "        self.metadata = []  # 存儲元數據\n",
    "    \n",
    "    def add_vectors(self, vectors: np.ndarray, texts: List[str], metadata: List[Dict]):\n",
    "        \"\"\"添加向量到索引\"\"\"\n",
    "        self.index.add(vectors.astype('float32'))\n",
    "        self.texts.extend(texts)\n",
    "        self.metadata.extend(metadata)\n",
    "        print(f\"已添加 {len(vectors)} 個向量到索引\")\n",
    "    \n",
    "    def search(self, query_vector: np.ndarray, k: int = 5) -> List[Dict]:\n",
    "        \"\"\"搜索最相似的向量\"\"\"\n",
    "        query_vector = query_vector.reshape(1, -1).astype('float32')\n",
    "        distances, indices = self.index.search(query_vector, k)\n",
    "        \n",
    "        results = []\n",
    "        for i, (distance, idx) in enumerate(zip(distances[0], indices[0])):\n",
    "            if idx < len(self.texts):  # 確保索引有效\n",
    "                results.append({\n",
    "                    'text': self.texts[idx],\n",
    "                    'metadata': self.metadata[idx],\n",
    "                    'distance': float(distance),\n",
    "                    'rank': i + 1\n",
    "                })\n",
    "        return results\n",
    "    \n",
    "    def get_stats(self) -> Dict:\n",
    "        \"\"\"獲取索引統計信息\"\"\"\n",
    "        return {\n",
    "            'total_vectors': self.index.ntotal,\n",
    "            'dimension': self.dimension,\n",
    "            'index_type': 'FlatL2'\n",
    "        }\n",
    "\n",
    "# 為訓練數據創建向量索引\n",
    "natural_language_queries = [item['natural_language'] for item in training_data]\n",
    "query_embeddings = embedder.encode(natural_language_queries)\n",
    "\n",
    "# 初始化向量索引\n",
    "vector_index = VectorIndex(query_embeddings.shape[1])\n",
    "\n",
    "# 添加向量到索引\n",
    "vector_index.add_vectors(\n",
    "    query_embeddings,\n",
    "    natural_language_queries,\n",
    "    training_data\n",
    ")\n",
    "\n",
    "print(\"向量索引統計:\")\n",
    "print(vector_index.get_stats())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 檢索系統\n",
    "\n",
    "### 實現語義檢索"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 實現檢索系統\n",
    "class SemanticRetriever:\n",
    "    def __init__(self, embedder: TextEmbedder, vector_index: VectorIndex, schema: DatabaseSchema):\n",
    "        \"\"\"初始化語義檢索器\"\"\"\n",
    "        self.embedder = embedder\n",
    "        self.vector_index = vector_index\n",
    "        self.schema = schema\n",
    "    \n",
    "    def retrieve(self, query: str, k: int = 3) -> List[Dict]:\n",
    "        \"\"\"檢索相關的SQL示例\"\"\"\n",
    "        # 1. 將查詢編碼為向量\n",
    "        query_vector = self.embedder.encode([query])[0]\n",
    "        \n",
    "        # 2. 在向量索引中搜索\n",
    "        similar_examples = self.vector_index.search(query_vector, k)\n",
    "        \n",
    "        # 3. 添加數據庫模式信息\n",
    "        schema_info = self.schema.get_schema_info()\n",
    "        \n",
    "        # 4. 構建檢索結果\n",
    "        retrieval_results = {\n",
    "            'query': query,\n",
    "            'schema_info': schema_info,\n",
    "            'similar_examples': similar_examples,\n",
    "            'retrieval_score': self._calculate_retrieval_score(similar_examples)\n",
    "        }\n",
    "        \n",
    "        return retrieval_results\n",
    "    \n",
    "    def _calculate_retrieval_score(self, examples: List[Dict]) -> float:\n",
    "        \"\"\"計算檢索質量分數\"\"\"\n",
    "        if not examples:\n",
    "            return 0.0\n",
    "        \n",
    "        # 基於距離計算分數（距離越小，分數越高）\n",
    "        distances = [ex['distance'] for ex in examples]\n",
    "        avg_distance = sum(distances) / len(distances)\n",
    "        score = max(0, 1 - avg_distance / 10)  # 簡單的評分公式\n",
    "        return score\n",
    "    \n",
    "    def explain_retrieval(self, results: Dict) -> str:\n",
    "        \"\"\"解釋檢索過程\"\"\"\n",
    "        explanation = f\"\\n檢索結果解釋：\\n\"\n",
    "        explanation += f\"查詢: {results['query']}\\n\"\n",
    "        explanation += f\"檢索分數: {results['retrieval_score']:.3f}\\n\"\n",
    "        explanation += f\"找到 {len(results['similar_examples'])} 個相似示例:\\n\"\n",
    "        \n",
    "        for i, example in enumerate(results['similar_examples']):\n",
    "            explanation += f\"\\n{i+1}. 相似度: {1-example['distance']:.3f}\\n\"\n",
    "            explanation += f\"   查詢: {example['text']}\\n\"\n",
    "            explanation += f\"   SQL: {example['metadata']['sql']}\\n\"\n",
    "        \n",
    "        return explanation\n",
    "\n",
    "# 初始化檢索器\n",
    "retriever = SemanticRetriever(embedder, vector_index, schema)\n",
    "\n",
    "# 測試檢索功能\n",
    "test_query = \"我要查看所有產品的詳細信息\"\n",
    "retrieval_results = retriever.retrieve(test_query)\n",
    "\n",
    "print(\"=== 檢索測試 ===\")\n",
    "print(retriever.explain_retrieval(retrieval_results))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. SQL 生成\n",
    "\n",
    "### 基於檢索結果生成SQL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# SQL生成器\n",
    "class SQLGenerator:\n",
    "    def __init__(self, schema: DatabaseSchema):\n",
    "        \"\"\"初始化SQL生成器\"\"\"\n",
    "        self.schema = schema\n",
    "        self.templates = self._load_sql_templates()\n",
    "    \n",
    "    def _load_sql_templates(self) -> Dict[str, str]:\n",
    "        \"\"\"加載SQL模板\"\"\"\n",
    "        return {\n",
    "            'select_all': \"SELECT * FROM {table};\",\n",
    "            'select_where': \"SELECT * FROM {table} WHERE {condition};\",\n",
    "            'count': \"SELECT COUNT(*) FROM {table};\",\n",
    "            'join': \"SELECT {columns} FROM {table1} t1 JOIN {table2} t2 ON {join_condition};\",\n",
    "            'group_by': \"SELECT {columns}, {aggregate} FROM {table} GROUP BY {group_columns};\",\n",
    "            'order_by': \"SELECT * FROM {table} ORDER BY {column} {direction};\"\n",
    "        }\n",
    "    \n",
    "    def generate_sql(self, query: str, retrieval_results: Dict) -> Dict:\n",
    "        \"\"\"基於檢索結果生成SQL\"\"\"\n",
    "        # 1. 分析查詢意圖\n",
    "        intent = self._analyze_intent(query)\n",
    "        \n",
    "        # 2. 從檢索結果中提取最佳匹配\n",
    "        best_match = retrieval_results['similar_examples'][0] if retrieval_results['similar_examples'] else None\n",
    "        \n",
    "        # 3. 生成SQL\n",
    "        if best_match and best_match['distance'] < 0.5:  # 高相似度\n",
    "            # 使用檢索到的SQL作為基礎\n",
    "            generated_sql = self._adapt_sql(best_match['metadata']['sql'], query)\n",
    "            method = 'retrieval_based'\n",
    "        else:\n",
    "            # 使用模板生成\n",
    "            generated_sql = self._template_based_generation(query, intent)\n",
    "            method = 'template_based'\n",
    "        \n",
    "        # 4. 驗證SQL\n",
    "        is_valid, validation_error = self._validate_sql(generated_sql)\n",
    "        \n",
    "        return {\n",
    "            'query': query,\n",
    "            'generated_sql': generated_sql,\n",
    "            'method': method,\n",
    "            'intent': intent,\n",
    "            'is_valid': is_valid,\n",
    "            'validation_error': validation_error,\n",
    "            'best_match': best_match\n",
    "        }\n",
    "    \n",
    "    def _analyze_intent(self, query: str) -> Dict:\n",
    "        \"\"\"分析查詢意圖\"\"\"\n",
    "        query_lower = query.lower()\n",
    "        \n",
    "        intent = {\n",
    "            'action': 'select',  # 默認為查詢\n",
    "            'tables': [],\n",
    "            'conditions': [],\n",
    "            'aggregation': None,\n",
    "            'sorting': None\n",
    "        }\n",
    "        \n",
    "        # 識別表名\n",
    "        for table in self.schema.tables.keys():\n",
    "            if table in query_lower or self._table_synonyms(table, query_lower):\n",
    "                intent['tables'].append(table)\n",
    "        \n",
    "        # 識別聚合操作\n",
    "        if any(word in query_lower for word in ['統計', '計算', '總和', '平均', '最大', '最小']):\n",
    "            intent['aggregation'] = 'count'  # 簡化處理\n",
    "        \n",
    "        # 識別排序\n",
    "        if any(word in query_lower for word in ['最', '排序', '最高', '最低']):\n",
    "            intent['sorting'] = 'desc' if '最高' in query_lower else 'asc'\n",
    "        \n",
    "        return intent\n",
    "    \n",
    "    def _table_synonyms(self, table: str, query: str) -> bool:\n",
    "        \"\"\"檢查表名同義詞\"\"\"\n",
    "        synonyms = {\n",
    "            'users': ['用戶', '使用者', '會員'],\n",
    "            'products': ['產品', '商品', '物品'],\n",
    "            'orders': ['訂單', '訂購', '購買']\n",
    "        }\n",
    "        \n",
    "        if table in synonyms:\n",
    "            return any(syn in query for syn in synonyms[table])\n",
    "        return False\n",
    "    \n",
    "    def _adapt_sql(self, base_sql: str, query: str) -> str:\n",
    "        \"\"\"調整基礎SQL以匹配新查詢\"\"\"\n",
    "        # 這裡可以實現更複雜的SQL調整邏輯\n",
    "        # 目前只是簡單返回基礎SQL\n",
    "        return base_sql\n",
    "    \n",
    "    def _template_based_generation(self, query: str, intent: Dict) -> str:\n",
    "        \"\"\"基於模板生成SQL\"\"\"\n",
    "        if not intent['tables']:\n",
    "            return \"SELECT 'No table identified' as error;\"\n",
    "        \n",
    "        table = intent['tables'][0]  # 使用第一個識別的表\n",
    "        \n",
    "        if intent['aggregation']:\n",
    "            return f\"SELECT COUNT(*) FROM {table};\"\n",
    "        elif intent['sorting']:\n",
    "            # 假設按第一個數值列排序\n",
    "            numeric_columns = self._get_numeric_columns(table)\n",
    "            if numeric_columns:\n",
    "                column = numeric_columns[0]\n",
    "                direction = intent['sorting'].upper()\n",
    "                return f\"SELECT * FROM {table} ORDER BY {column} {direction};\"\n",
    "        \n",
    "        return f\"SELECT * FROM {table};\"\n",
    "    \n",
    "    def _get_numeric_columns(self, table: str) -> List[str]:\n",
    "        \"\"\"獲取表中的數值列\"\"\"\n",
    "        if table not in self.schema.tables:\n",
    "            return []\n",
    "        \n",
    "        numeric_types = ['INT', 'DECIMAL', 'FLOAT', 'DOUBLE']\n",
    "        numeric_columns = []\n",
    "        \n",
    "        for column, column_type in self.schema.tables[table].items():\n",
    "            if any(num_type in column_type.upper() for num_type in numeric_types):\n",
    "                numeric_columns.append(column)\n",
    "        \n",
    "        return numeric_columns\n",
    "    \n",
    "    def _validate_sql(self, sql: str) -> Tuple[bool, str]:\n",
    "        \"\"\"驗證SQL語法\"\"\"\n",
    "        try:\n",
    "            parsed = sqlparse.parse(sql)[0]\n",
    "            if parsed.tokens:\n",
    "                return True, \"\"\n",
    "            else:\n",
    "                return False, \"Empty SQL statement\"\n",
    "        except Exception as e:\n",
    "            return False, str(e)\n",
    "\n",
    "# 初始化SQL生成器\n",
    "sql_generator = SQLGenerator(schema)\n",
    "\n",
    "# 測試SQL生成\n",
    "test_queries = [\n",
    "    \"顯示所有產品信息\",\n",
    "    \"找出最貴的產品\",\n",
    "    \"統計用戶數量\"\n",
    "]\n",
    "\n",
    "print(\"=== SQL生成測試 ===\")\n",
    "for query in test_queries:\n",
    "    retrieval_results = retriever.retrieve(query)\n",
    "    generation_results = sql_generator.generate_sql(query, retrieval_results)\n",
    "    \n",
    "    print(f\"\\n查詢: {query}\")\n",
    "    print(f\"生成的SQL: {generation_results['generated_sql']}\")\n",
    "    print(f\"生成方法: {generation_results['method']}\")\n",
    "    print(f\"SQL有效性: {generation_results['is_valid']}\")\n",
    "    if generation_results['validation_error']:\n",
    "        print(f\"驗證錯誤: {generation_results['validation_error']}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 8. 完整流水線\n",
    "\n",
    "### 整合所有組件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 完整的TextSQL RAG流水線\n",
    "class TextSQLRAGPipeline:\n",
    "    def __init__(self, \n",
    "                 embedder: TextEmbedder,\n",
    "                 vector_index: VectorIndex,\n",
    "                 schema: DatabaseSchema,\n",
    "                 retriever: SemanticRetriever,\n",
    "                 sql_generator: SQLGenerator):\n",
    "        \"\"\"初始化完整的RAG流水線\"\"\"\n",
    "        self.embedder = embedder\n",
    "        self.vector_index = vector_index\n",
    "        self.schema = schema\n",
    "        self.retriever = retriever\n",
    "        self.sql_generator = sql_generator\n",
    "        self.query_history = []\n",
    "    \n",
    "    def process_query(self, natural_language_query: str, execute_sql: bool = False) -> Dict:\n",
    "        \"\"\"處理自然語言查詢的完整流程\"\"\"\n",
    "        print(f\"\\n處理查詢: {natural_language_query}\")\n",
    "        \n",
    "        # 第1步：檢索相關示例\n",
    "        print(\"第1步：檢索相關示例...\")\n",
    "        retrieval_results = self.retriever.retrieve(natural_language_query)\n",
    "        \n",
    "        # 第2步：生成SQL\n",
    "        print(\"第2步：生成SQL...\")\n",
    "        generation_results = self.sql_generator.generate_sql(natural_language_query, retrieval_results)\n",
    "        \n",
    "        # 第3步：執行SQL（可選）\n",
    "        execution_results = None\n",
    "        if execute_sql and generation_results['is_valid']:\n",
    "            print(\"第3步：執行SQL...\")\n",
    "            execution_results = self._execute_sql(generation_results['generated_sql'])\n",
    "        \n",
    "        # 第4步：構建完整結果\n",
    "        complete_results = {\n",
    "            'natural_language_query': natural_language_query,\n",
    "            'retrieval_results': retrieval_results,\n",
    "            'generation_results': generation_results,\n",
    "            'execution_results': execution_results,\n",
    "            'pipeline_success': generation_results['is_valid'],\n",
    "            'timestamp': pd.Timestamp.now().isoformat()\n",
    "        }\n",
    "        \n",
    "        # 第5步：記錄查詢歷史\n",
    "        self.query_history.append(complete_results)\n",
    "        \n",
    "        return complete_results\n",
    "    \n",
    "    def _execute_sql(self, sql: str) -> Dict:\n",
    "        \"\"\"執行SQL查詢\"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect('sample_ecommerce.db')\n",
    "            \n",
    "            # 執行查詢\n",
    "            result_df = pd.read_sql_query(sql, conn)\n",
    "            \n",
    "            conn.close()\n",
    "            \n",
    "            return {\n",
    "                'success': True,\n",
    "                'data': result_df.to_dict('records'),\n",
    "                'row_count': len(result_df),\n",
    "                'columns': list(result_df.columns),\n",
    "                'error': None\n",
    "            }\n",
    "        \n",
    "        except Exception as e:\n",
    "            return {\n",
    "                'success': False,\n",
    "                'data': None,\n",
    "                'row_count': 0,\n",
    "                'columns': [],\n",
    "                'error': str(e)\n",
    "            }\n",
    "    \n",
    "    def explain_results(self, results: Dict) -> str:\n",
    "        \"\"\"解釋處理結果\"\"\"\n",
    "        explanation = f\"\\n{'='*50}\\n\"\n",
    "        explanation += f\"查詢: {results['natural_language_query']}\\n\"\n",
    "        explanation += f\"{'='*50}\\n\"\n",
    "        \n",
    "        # 檢索階段\n",
    "        explanation += \"\\n🔍 檢索階段:\\n\"\n",
    "        retrieval = results['retrieval_results']\n",
    "        explanation += f\"找到 {len(retrieval['similar_examples'])} 個相似示例\\n\"\n",
    "        explanation += f\"檢索分數: {retrieval['retrieval_score']:.3f}\\n\"\n",
    "        \n",
    "        if retrieval['similar_examples']:\n",
    "            best_match = retrieval['similar_examples'][0]\n",
    "            explanation += f\"最佳匹配: {best_match['text']} (相似度: {1-best_match['distance']:.3f})\\n\"\n",
    "        \n",
    "        # 生成階段\n",
    "        explanation += \"\\n⚙️ 生成階段:\\n\"\n",
    "        generation = results['generation_results']\n",
    "        explanation += f\"生成方法: {generation['method']}\\n\"\n",
    "        explanation += f\"生成的SQL: {generation['generated_sql']}\\n\"\n",
    "        explanation += f\"SQL有效性: {generation['is_valid']}\\n\"\n",
    "        \n",
    "        # 執行階段\n",
    "        if results['execution_results']:\n",
    "            explanation += \"\\n🚀 執行階段:\\n\"\n",
    "            execution = results['execution_results']\n",
    "            if execution['success']:\n",
    "                explanation += f\"執行成功，返回 {execution['row_count']} 行數據\\n\"\n",
    "                if execution['data']:\n",
    "                    explanation += \"前幾行數據:\\n\"\n",
    "                    for i, row in enumerate(execution['data'][:3]):\n",
    "                        explanation += f\"  {i+1}: {row}\\n\"\n",
    "            else:\n",
    "                explanation += f\"執行失敗: {execution['error']}\\n\"\n",
    "        \n",
    "        explanation += f\"\\n✅ 流水線成功: {results['pipeline_success']}\\n\"\n",
    "        \n",
    "        return explanation\n",
    "    \n",
    "    def get_pipeline_stats(self) -> Dict:\n",
    "        \"\"\"獲取流水線統計信息\"\"\"\n",
    "        if not self.query_history:\n",
    "            return {'total_queries': 0}\n",
    "        \n",
    "        successful_queries = sum(1 for q in self.query_history if q['pipeline_success'])\n",
    "        \n",
    "        return {\n",
    "            'total_queries': len(self.query_history),\n",
    "            'successful_queries': successful_queries,\n",
    "            'success_rate': successful_queries / len(self.query_history),\n",
    "            'avg_retrieval_score': np.mean([q['retrieval_results']['retrieval_score'] \n",
    "                                          for q in self.query_history])\n",
    "        }\n",
    "\n",
    "# 初始化完整流水線\n",
    "pipeline = TextSQLRAGPipeline(\n",
    "    embedder=embedder,\n",
    "    vector_index=vector_index,\n",
    "    schema=schema,\n",
    "    retriever=retriever,\n",
    "    sql_generator=sql_generator\n",
    ")\n",
    "\n",
    "print(\"✅ TextSQL RAG 流水線初始化完成！\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 流水線演示"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 流水線演示\n",
    "demo_queries = [\n",
    "    \"顯示所有用戶的基本信息\",\n",
    "    \"查找價格最高的產品\",\n",
    "    \"統計每個類別有多少產品\",\n",
    "    \"顯示張三購買的所有商品\",\n",
    "    \"找出還沒有下過訂單的用戶\"\n",
    "]\n",
    "\n",
    "print(\"🚀 開始流水線演示\\n\")\n",
    "\n",
    "for i, query in enumerate(demo_queries, 1):\n",
    "    print(f\"\\n{'='*60}\")\n",
    "    print(f\"演示 {i}/{len(demo_queries)}\")\n",
    "    print(f\"{'='*60}\")\n",
    "    \n",
    "    # 處理查詢\n",
    "    results = pipeline.process_query(query, execute_sql=True)\n",
    "    \n",
    "    # 顯示結果\n",
    "    print(pipeline.explain_results(results))\n",
    "    \n",
    "    # 暫停一下讓輸出更清晰\n",
    "    import time\n",
    "    time.sleep(1)\n",
    "\n",
    "# 顯示整體統計\n",
    "print(\"\\n\" + \"=\"*60)\n",
    "print(\"流水線統計\")\n",
    "print(\"=\"*60)\n",
    "stats = pipeline.get_pipeline_stats()\n",
    "for key, value in stats.items():\n",
    "    print(f\"{key}: {value}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 9. 評估與優化\n",
    "\n",
    "### 評估指標"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 評估系統\n",
    "class RAGEvaluator:\n",
    "    def __init__(self, pipeline: TextSQLRAGPipeline):\n",
    "        \"\"\"初始化評估器\"\"\"\n",
    "        self.pipeline = pipeline\n",
    "    \n",
    "    def evaluate_retrieval(self, test_cases: List[Dict]) -> Dict:\n",
    "        \"\"\"評估檢索性能\"\"\"\n",
    "        retrieval_scores = []\n",
    "        precision_scores = []\n",
    "        \n",
    "        for test_case in test_cases:\n",
    "            query = test_case['natural_language']\n",
    "            expected_sql = test_case['sql']\n",
    "            \n",
    "            # 檢索相關示例\n",
    "            retrieval_results = self.pipeline.retriever.retrieve(query)\n",
    "            \n",
    "            # 計算檢索分數\n",
    "            retrieval_scores.append(retrieval_results['retrieval_score'])\n",
    "            \n",
    "            # 計算精確度（檢索結果中是否包含正確答案）\n",
    "            precision = self._calculate_precision(retrieval_results, expected_sql)\n",
    "            precision_scores.append(precision)\n",
    "        \n",
    "        return {\n",
    "            'avg_retrieval_score': np.mean(retrieval_scores),\n",
    "            'avg_precision': np.mean(precision_scores),\n",
    "            'retrieval_scores': retrieval_scores,\n",
    "            'precision_scores': precision_scores\n",
    "        }\n",
    "    \n",
    "    def evaluate_generation(self, test_cases: List[Dict]) -> Dict:\n",
    "        \"\"\"評估SQL生成性能\"\"\"\n",
    "        exact_match_scores = []\n",
    "        syntax_valid_scores = []\n",
    "        semantic_similarity_scores = []\n",
    "        \n",
    "        for test_case in test_cases:\n",
    "            query = test_case['natural_language']\n",
    "            expected_sql = test_case['sql']\n",
    "            \n",
    "            # 生成SQL\n",
    "            results = self.pipeline.process_query(query, execute_sql=False)\n",
    "            generated_sql = results['generation_results']['generated_sql']\n",
    "            \n",
    "            # 精確匹配\n",
    "            exact_match = self._normalize_sql(generated_sql) == self._normalize_sql(expected_sql)\n",
    "            exact_match_scores.append(exact_match)\n",
    "            \n",
    "            # 語法有效性\n",
    "            syntax_valid = results['generation_results']['is_valid']\n",
    "            syntax_valid_scores.append(syntax_valid)\n",
    "            \n",
    "            # 語義相似度（簡化實現）\n",
    "            semantic_sim = self._calculate_semantic_similarity(generated_sql, expected_sql)\n",
    "            semantic_similarity_scores.append(semantic_sim)\n",
    "        \n",
    "        return {\n",
    "            'exact_match_rate': np.mean(exact_match_scores),\n",
    "            'syntax_valid_rate': np.mean(syntax_valid_scores),\n",
    "            'avg_semantic_similarity': np.mean(semantic_similarity_scores),\n",
    "            'exact_match_scores': exact_match_scores,\n",
    "            'syntax_valid_scores': syntax_valid_scores,\n",
    "            'semantic_similarity_scores': semantic_similarity_scores\n",
    "        }\n",
    "    \n",
    "    def evaluate_end_to_end(self, test_cases: List[Dict]) -> Dict:\n",
    "        \"\"\"端到端評估\"\"\"\n",
    "        execution_success_scores = []\n",
    "        result_accuracy_scores = []\n",
    "        \n",
    "        for test_case in test_cases:\n",
    "            query = test_case['natural_language']\n",
    "            expected_sql = test_case['sql']\n",
    "            \n",
    "            # 執行完整流水線\n",
    "            results = self.pipeline.process_query(query, execute_sql=True)\n",
    "            \n",
    "            # 執行成功率\n",
    "            execution_success = (\n",
    "                results['execution_results'] is not None and \n",
    "                results['execution_results']['success']\n",
    "            )\n",
    "            execution_success_scores.append(execution_success)\n",
    "            \n",
    "            # 結果准確性（通過執行期望SQL進行比較）\n",
    "            if execution_success:\n",
    "                result_accuracy = self._compare_execution_results(\n",
    "                    results['generation_results']['generated_sql'],\n",
    "                    expected_sql\n",
    "                )\n",
    "                result_accuracy_scores.append(result_accuracy)\n",
    "            else:\n",
    "                result_accuracy_scores.append(0.0)\n",
    "        \n",
    "        return {\n",
    "            'execution_success_rate': np.mean(execution_success_scores),\n",
    "            'result_accuracy_rate': np.mean(result_accuracy_scores),\n",
    "            'execution_success_scores': execution_success_scores,\n",
    "            'result_accuracy_scores': result_accuracy_scores\n",
    "        }\n",
    "    \n",
    "    def _calculate_precision(self, retrieval_results: Dict, expected_sql: str) -> float:\n",
    "        \"\"\"計算檢索精確度\"\"\"\n",
    "        similar_examples = retrieval_results['similar_examples']\n",
    "        if not similar_examples:\n",
    "            return 0.0\n",
    "        \n",
    "        # 檢查是否有檢索結果與期望SQL相似\n",
    "        for example in similar_examples:\n",
    "            if self._sql_similarity(example['metadata']['sql'], expected_sql) > 0.8:\n",
    "                return 1.0\n",
    "        \n",
    "        return 0.0\n",
    "    \n",
    "    def _normalize_sql(self, sql: str) -> str:\n",
    "        \"\"\"標準化SQL字符串\"\"\"\n",
    "        # 移除多餘空格，轉換為小寫\n",
    "        return ' '.join(sql.lower().split())\n",
    "    \n",
    "    def _calculate_semantic_similarity(self, sql1: str, sql2: str) -> float:\n",
    "        \"\"\"計算SQL語義相似度\"\"\"\n",
    "        # 簡化實現：基於關鍵詞重疊\n",
    "        words1 = set(self._normalize_sql(sql1).split())\n",
    "        words2 = set(self._normalize_sql(sql2).split())\n",
    "        \n",
    "        if not words1 and not words2:\n",
    "            return 1.0\n",
    "        if not words1 or not words2:\n",
    "            return 0.0\n",
    "        \n",
    "        intersection = words1.intersection(words2)\n",
    "        union = words1.union(words2)\n",
    "        \n",
    "        return len(intersection) / len(union)\n",
    "    \n",
    "    def _sql_similarity(self, sql1: str, sql2: str) -> float:\n",
    "        \"\"\"計算SQL相似度\"\"\"\n",
    "        return self._calculate_semantic_similarity(sql1, sql2)\n",
    "    \n",
    "    def _compare_execution_results(self, generated_sql: str, expected_sql: str) -> float:\n",
    "        \"\"\"比較執行結果\"\"\"\n",
    "        try:\n",
    "            conn = sqlite3.connect('sample_ecommerce.db')\n",
    "            \n",
    "            # 執行兩個SQL\n",
    "            result1 = pd.read_sql_query(generated_sql, conn)\n",
    "            result2 = pd.read_sql_query(expected_sql, conn)\n",
    "            \n",
    "            conn.close()\n",
    "            \n",
    "            # 比較結果\n",
    "            if result1.equals(result2):\n",
    "                return 1.0\n",
    "            elif len(result1) == len(result2) and len(result1.columns) == len(result2.columns):\n",
    "                return 0.5  # 部分匹配\n",
    "            else:\n",
    "                return 0.0\n",
    "                \n",
    "        except Exception:\n",
    "            return 0.0\n",
    "    \n",
    "    def generate_evaluation_report(self, test_cases: List[Dict]) -> str:\n",
    "        \"\"\"生成評估報告\"\"\"\n",
    "        retrieval_eval = self.evaluate_retrieval(test_cases)\n",
    "        generation_eval = self.evaluate_generation(test_cases)\n",
    "        e2e_eval = self.evaluate_end_to_end(test_cases)\n",
    "        \n",
    "        report = \"\\n\" + \"=\"*50 + \"\\n\"\n",
    "        report += \"TextSQL RAG Pipeline 評估報告\\n\"\n",
    "        report += \"=\"*50 + \"\\n\"\n",
    "        \n",
    "        report += \"\\n📊 檢索性能:\\n\"\n",
    "        report += f\"  平均檢索分數: {retrieval_eval['avg_retrieval_score']:.3f}\\n\"\n",
    "        report += f\"  平均精確度: {retrieval_eval['avg_precision']:.3f}\\n\"\n",
    "        \n",
    "        report += \"\\n🔧 生成性能:\\n\"\n",
    "        report += f\"  精確匹配率: {generation_eval['exact_match_rate']:.3f}\\n\"\n",
    "        report += f\"  語法有效率: {generation_eval['syntax_valid_rate']:.3f}\\n\"\n",
    "        report += f\"  平均語義相似度: {generation_eval['avg_semantic_similarity']:.3f}\\n\"\n",
    "        \n",
    "        report += \"\\n🚀 端到端性能:\\n\"\n",
    "        report += f\"  執行成功率: {e2e_eval['execution_success_rate']:.3f}\\n\"\n",
    "        report += f\"  結果准確率: {e2e_eval['result_accuracy_rate']:.3f}\\n\"\n",
    "        \n",
    "        # 總體評分\n",
    "        overall_score = np.mean([\n",
    "            retrieval_eval['avg_retrieval_score'],\n",
    "            generation_eval['syntax_valid_rate'],\n",
    "            e2e_eval['execution_success_rate']\n",
    "        ])\n",
    "        \n",
    "        report += f\"\\n⭐ 總體評分: {overall_score:.3f}\\n\"\n",
    "        \n",
    "        return report\n",
    "\n",
    "# 創建評估器\n",
    "evaluator = RAGEvaluator(pipeline)\n",
    "\n",
    "# 運行評估\n",
    "print(\"🔍 開始評估流水線性能...\")\n",
    "evaluation_report = evaluator.generate_evaluation_report(training_data)\n",
    "print(evaluation_report)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 10. 實際應用案例\n",
    "\n",
    "### 互動式查詢界面"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 互動式查詢界面\n",
    "class InteractiveQueryInterface:\n",
    "    def __init__(self, pipeline: TextSQLRAGPipeline):\n",
    "        \"\"\"初始化互動式界面\"\"\"\n",
    "        self.pipeline = pipeline\n",
    "        self.session_history = []\n",
    "    \n",
    "    def start_session(self):\n",
    "        \"\"\"開始互動會話\"\"\"\n",
    "        print(\"\\n🎯 歡迎使用 TextSQL RAG 查詢系統！\")\n",
    "        print(\"輸入自然語言查詢，系統將生成對應的SQL語句並執行\")\n",
    "        print(\"輸入 'help' 查看幫助，輸入 'quit' 退出系統\\n\")\n",
    "        \n",
    "        while True:\n",
    "            try:\n",
    "                user_input = input(\"🔍 請輸入您的查詢: \").strip()\n",
    "                \n",
    "                if user_input.lower() == 'quit':\n",
    "                    print(\"👋 感謝使用，再見！\")\n",
    "                    break\n",
    "                elif user_input.lower() == 'help':\n",
    "                    self._show_help()\n",
    "                    continue\n",
    "                elif user_input.lower() == 'history':\n",
    "                    self._show_history()\n",
    "                    continue\n",
    "                elif user_input.lower() == 'schema':\n",
    "                    self._show_schema()\n",
    "                    continue\n",
    "                elif not user_input:\n",
    "                    continue\n",
    "                \n",
    "                # 處理查詢\n",
    "                self._process_interactive_query(user_input)\n",
    "                \n",
    "            except KeyboardInterrupt:\n",
    "                print(\"\\n👋 用戶中斷，再見！\")\n",
    "                break\n",
    "            except Exception as e:\n",
    "                print(f\"❌ 發生錯誤: {e}\")\n",
    "    \n",
    "    def _process_interactive_query(self, query: str):\n",
    "        \"\"\"處理互動查詢\"\"\"\n",
    "        print(f\"\\n⏳ 處理中...\")\n",
    "        \n",
    "        # 執行查詢\n",
    "        results = self.pipeline.process_query(query, execute_sql=True)\n",
    "        \n",
    "        # 記錄會話歷史\n",
    "        self.session_history.append(results)\n",
    "        \n",
    "        # 顯示結果\n",
    "        self._display_results(results)\n",
    "    \n",
    "    def _display_results(self, results: Dict):\n",
    "        \"\"\"顯示查詢結果\"\"\"\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(f\"📝 查詢: {results['natural_language_query']}\")\n",
    "        print(\"=\"*50)\n",
    "        \n",
    "        # 顯示生成的SQL\n",
    "        generation = results['generation_results']\n",
    "        print(f\"\\n💻 生成的SQL:\")\n",
    "        print(f\"```sql\\n{generation['generated_sql']}\\n```\")\n",
    "        \n",
    "        print(f\"\\n🔧 生成方法: {generation['method']}\")\n",
    "        print(f\"✅ SQL有效性: {generation['is_valid']}\")\n",
    "        \n",
    "        # 顯示執行結果\n",
    "        if results['execution_results']:\n",
    "            execution = results['execution_results']\n",
    "            if execution['success']:\n",
    "                print(f\"\\n🎯 執行結果: 成功返回 {execution['row_count']} 行數據\")\n",
    "                \n",
    "                if execution['data']:\n",
    "                    # 將結果格式化為表格\n",
    "                    df = pd.DataFrame(execution['data'])\n",
    "                    print(\"\\n📊 查詢結果:\")\n",
    "                    print(df.to_string(index=False))\n",
    "                else:\n",
    "                    print(\"\\n📊 查詢結果: 無數據返回\")\n",
    "            else:\n",
    "                print(f\"\\n❌ 執行失敗: {execution['error']}\")\n",
    "        \n",
    "        # 顯示檢索信息\n",
    "        retrieval = results['retrieval_results']\n",
    "        if retrieval['similar_examples']:\n",
    "            best_match = retrieval['similar_examples'][0]\n",
    "            print(f\"\\n🔍 最佳匹配示例: {best_match['text']}\")\n",
    "            print(f\"📈 相似度: {1-best_match['distance']:.3f}\")\n",
    "    \n",
    "    def _show_help(self):\n",
    "        \"\"\"顯示幫助信息\"\"\"\n",
    "        help_text = \"\"\"\n",
    "📚 使用幫助:\n",
    "\n",
    "基本查詢示例:\n",
    "  • \"顯示所有用戶\" - 查詢用戶表\n",
    "  • \"找出最貴的產品\" - 按價格排序\n",
    "  • \"統計每個類別的產品數量\" - 聚合查詢\n",
    "  • \"顯示張三的所有訂單\" - 聯合查詢\n",
    "\n",
    "特殊命令:\n",
    "  • help - 顯示此幫助\n",
    "  • history - 顯示查詢歷史\n",
    "  • schema - 顯示數據庫結構\n",
    "  • quit - 退出系統\n",
    "\n",
    "💡 提示: 盡量使用自然語言描述您的查詢需求！\n",
    "\"\"\"\n",
    "        print(help_text)\n",
    "    \n",
    "    def _show_history(self):\n",
    "        \"\"\"顯示查詢歷史\"\"\"\n",
    "        if not self.session_history:\n",
    "            print(\"\\n📝 暫無查詢歷史\")\n",
    "            return\n",
    "        \n",
    "        print(f\"\\n📝 查詢歷史 (共 {len(self.session_history)} 條):\")\n",
    "        print(\"-\" * 60)\n",
    "        \n",
    "        for i, result in enumerate(self.session_history[-5:], 1):  # 只顯示最近5條\n",
    "            query = result['natural_language_query']\n",
    "            sql = result['generation_results']['generated_sql']\n",
    "            success = result['pipeline_success']\n",
    "            status = \"✅\" if success else \"❌\"\n",
    "            \n",
    "            print(f\"{i}. {status} {query}\")\n",
    "            print(f\"   SQL: {sql[:50]}{'...' if len(sql) > 50 else ''}\")\n",
    "            print()\n",
    "    \n",
    "    def _show_schema(self):\n",
    "        \"\"\"顯示數據庫結構\"\"\"\n",
    "        print(\"\\n🗃️ 數據庫結構:\")\n",
    "        print(self.pipeline.schema.get_schema_info())\n",
    "\n",
    "# 創建互動界面\n",
    "interface = InteractiveQueryInterface(pipeline)\n",
    "\n",
    "# 演示一些自動查詢（而不是真正的互動模式）\n",
    "print(\"\\n🎯 TextSQL RAG 系統演示\")\n",
    "print(\"以下是一些自動執行的查詢示例:\\n\")\n",
    "\n",
    "demo_queries = [\n",
    "    \"查看所有用戶的信息\",\n",
    "    \"找出價格最高的三個產品\",\n",
    "    \"統計每個用戶的訂單總數\"\n",
    "]\n",
    "\n",
    "for query in demo_queries:\n",
    "    print(f\"🔍 查詢: {query}\")\n",
    "    interface._process_interactive_query(query)\n",
    "    print(\"\\n\" + \"-\"*60 + \"\\n\")\n",
    "\n",
    "print(\"\\n✨ 演示完成！要開始真正的互動模式，請取消註釋下面的代碼：\")\n",
    "print(\"# interface.start_session()\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 總結與優化建議\n",
    "\n",
    "### 學習總結\n",
    "\n",
    "通過本筆記本，我們完整實現了一個 TextSQL RAG 流水線，包括：\n",
    "\n",
    "1. **數據預處理**: 創建示例數據庫和訓練數據\n",
    "2. **向量化**: 使用句子嵌入模型將文本轉換為向量\n",
    "3. **檢索系統**: 基於語義相似度檢索相關示例\n",
    "4. **SQL生成**: 結合檢索結果和模板生成SQL\n",
    "5. **完整流水線**: 整合所有組件\n",
    "6. **評估系統**: 多維度評估性能\n",
    "7. **實際應用**: 互動式查詢界面\n",
    "\n",
    "### 優化建議\n",
    "\n",
    "1. **模型優化**:\n",
    "   - 使用更強大的嵌入模型（如 OpenAI embeddings）\n",
    "   - 實現微調機制以適應特定領域\n",
    "\n",
    "2. **檢索優化**:\n",
    "   - 實現混合檢索（語義+關鍵詞）\n",
    "   - 添加重排序機制\n",
    "\n",
    "3. **生成優化**:\n",
    "   - 集成大語言模型（如 GPT-4）\n",
    "   - 實現更複雜的SQL模板\n",
    "\n",
    "4. **系統優化**:\n",
    "   - 添加緩存機制\n",
    "   - 實現分佈式部署\n",
    "   - 增強錯誤處理\n",
    "\n",
    "### 後續學習方向\n",
    "\n",
    "1. 深入學習 Transformer 架構\n",
    "2. 探索更高級的 RAG 技術\n",
    "3. 學習數據庫優化技術\n",
    "4. 研究多模態 RAG 系統"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 保存流水線狀態和結果\n",
    "import pickle\n",
    "\n",
    "def save_pipeline_state():\n",
    "    \"\"\"保存流水線狀態\"\"\"\n",
    "    state = {\n",
    "        'query_history': pipeline.query_history,\n",
    "        'pipeline_stats': pipeline.get_pipeline_stats(),\n",
    "        'training_data': training_data,\n",
    "        'schema_info': schema.get_schema_info()\n",
    "    }\n",
    "    \n",
    "    with open('pipeline_state.pkl', 'wb') as f:\n",
    "        pickle.dump(state, f)\n",
    "    \n",
    "    # 也保存為JSON格式便於查看\n",
    "    json_state = {\n",
    "        'pipeline_stats': pipeline.get_pipeline_stats(),\n",
    "        'training_data': training_data,\n",
    "        'schema_info': schema.get_schema_info()\n",
    "    }\n",
    "    \n",
    "    with open('pipeline_summary.json', 'w', encoding='utf-8') as f:\n",
    "        json.dump(json_state, f, ensure_ascii=False, indent=2)\n",
    "    \n",
    "    print(\"✅ 流水線狀態已保存\")\n",
    "\n",
    "# 保存狀態\n",
    "save_pipeline_state()\n",
    "\n",
    "print(\"\\n🎉 TextSQL RAG Pipeline 學習筆記完成！\")\n",
    "print(\"\\n📝 學習成果:\")\n",
    "print(f\"  • 處理了 {len(pipeline.query_history)} 個查詢\")\n",
    "print(f\"  • 成功率: {pipeline.get_pipeline_stats().get('success_rate', 0):.1%}\")\n",
    "print(f\"  • 平均檢索分數: {pipeline.get_pipeline_stats().get('avg_retrieval_score', 0):.3f}\")\n",
    "print(\"\\n🚀 您現在可以:\")\n",
    "print(\"  1. 在 Kaggle 環境中運行此筆記本\")\n",
    "print(\"  2. 修改數據庫結構和訓練數據\")\n",
    "print(\"  3. 優化檢索和生成算法\")\n",
    "print(\"  4. 集成更強大的語言模型\")\n",
    "print(\"\\n💡 建議下一步: 嘗試在真實數據集上測試此系統！\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
